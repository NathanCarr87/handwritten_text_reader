{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handwritten_text_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NathanCarr87/handwritten_text_reader/blob/master/handwritten_text_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "575Xla0Fixas"
      },
      "cell_type": "markdown",
      "source": [
        "#HandWrittend Text Recognition\n",
        "\n",
        "## Derived from https://towardsdatascience.com/build-a-handwritten-text-recognition-system-using-tensorflow-2326a3487cd5\n",
        "## #https://github.com/githubharald/SimpleHTR"
      ]
    },
    {
      "metadata": {
        "id": "UH8DXN2C3MHI",
        "colab_type": "code",
        "outputId": "b5f65752-f3bd-481e-aa38-6ab42071d0f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EvLgYfPUixap",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import editdistance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "quLe7d0Bixan"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qLX0Mficixai",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(img, imgSize, dataAugmentation=False):\n",
        "\t\"put img into target img of size imgSize, transpose for TF and normalize gray-values\"\n",
        "\n",
        "\t# there are damaged files in IAM dataset - just use black image instead\n",
        "\tif img is None:\n",
        "\t\timg = np.zeros([imgSize[1], imgSize[0]])\n",
        "\n",
        "\t# increase dataset size by applying random stretches to the images\n",
        "\tif dataAugmentation:\n",
        "\t\tstretch = (random.random() - 0.5) # -0.5 .. +0.5\n",
        "\t\twStretched = max(int(img.shape[1] * (1 + stretch)), 1) # random width, but at least 1\n",
        "\t\timg = cv2.resize(img, (wStretched, img.shape[0])) # stretch horizontally by factor 0.5 .. 1.5\n",
        "\t\n",
        "\t# create target image and copy sample image into it\n",
        "\t(wt, ht) = imgSize\n",
        "\t(h, w) = img.shape\n",
        "\tfx = w / wt\n",
        "\tfy = h / ht\n",
        "\tf = max(fx, fy)\n",
        "\tnewSize = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1)) # scale according to f (result at least 1 and at most wt or ht)\n",
        "\timg = cv2.resize(img, newSize)\n",
        "\ttarget = np.ones([ht, wt]) * 255\n",
        "\ttarget[0:newSize[1], 0:newSize[0]] = img\n",
        "\n",
        "\t# transpose for TF\n",
        "\timg = cv2.transpose(target)\n",
        "\n",
        "\t# normalize\n",
        "\t(m, s) = cv2.meanStdDev(img)\n",
        "\tm = m[0][0]\n",
        "\ts = s[0][0]\n",
        "\timg = img - m\n",
        "\timg = img / s if s>0 else img\n",
        "\treturn img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zAHgmRT3i0pZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Data Loader"
      ]
    },
    {
      "metadata": {
        "id": "KJOruj32i2mn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Sample:\n",
        "\t\"sample from the dataset\"\n",
        "\tdef __init__(self, gtText, filePath):\n",
        "\t\tself.gtText = gtText\n",
        "\t\tself.filePath = filePath\n",
        "\n",
        "\n",
        "class Batch:\n",
        "\t\"batch containing images and ground truth texts\"\n",
        "\tdef __init__(self, gtTexts, imgs):\n",
        "\t\tself.imgs = np.stack(imgs, axis=0)\n",
        "\t\tself.gtTexts = gtTexts\n",
        "\n",
        "\n",
        "class DataLoader:\n",
        "\t\"loads data which corresponds to IAM format, see: http://www.fki.inf.unibe.ch/databases/iam-handwriting-database\" \n",
        "\n",
        "\tdef __init__(self, filePath, batchSize, imgSize, maxTextLen):\n",
        "\t\t\"loader for dataset at given location, preprocess images and text according to parameters\"\n",
        "\n",
        "\t\tassert filePath[-1]=='/'\n",
        "\n",
        "\t\tself.dataAugmentation = False\n",
        "\t\tself.currIdx = 0\n",
        "\t\tself.batchSize = batchSize\n",
        "\t\tself.imgSize = imgSize\n",
        "\t\tself.samples = []\n",
        "\t\n",
        "\t\tf=open(filePath+'words.txt')\n",
        "\t\tchars = set()\n",
        "\t\tbad_samples = []\n",
        "\t\tbad_samples_reference = ['a01-117-05-02.png', 'r06-022-03-05.png']\n",
        "\t\tfor line in f:\n",
        "\t\t\t# ignore comment line\n",
        "\t\t\tif not line or line[0]=='#':\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t\n",
        "\t\t\tlineSplit = line.strip().split(' ')\n",
        "\t\t\tassert len(lineSplit) >= 9\n",
        "\t\t\t\n",
        "\t\t\t# filename: part1-part2-part3 --> part1/part1-part2/part1-part2-part3.png\n",
        "\t\t\tfileNameSplit = lineSplit[0].split('-')\n",
        "\t\t\tfileName = filePath + 'words/' + fileNameSplit[0] + '/' + fileNameSplit[0] + '-' + fileNameSplit[1] + '/' + lineSplit[0] + '.png'\n",
        "\n",
        "\t\t\t# GT text are columns starting at 9\n",
        "\t\t\tgtText = self.truncateLabel(' '.join(lineSplit[8:]), maxTextLen)\n",
        "\t\t\tchars = chars.union(set(list(gtText)))\n",
        "\n",
        "\t\t\t# check if image is not empty\n",
        "\t\t\tif not os.path.getsize(fileName):\n",
        "\t\t\t\tbad_samples.append(lineSplit[0] + '.png')\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t# put sample into list\n",
        "\t\t\tself.samples.append(Sample(gtText, fileName))\n",
        "\n",
        "\t\t# some images in the IAM dataset are known to be damaged, don't show warning for them\n",
        "\t\tif set(bad_samples) != set(bad_samples_reference):\n",
        "\t\t\tprint(\"Warning, damaged images found:\", bad_samples)\n",
        "\t\t\tprint(\"Damaged images expected:\", bad_samples_reference)\n",
        "\n",
        "\t\t# split into training and validation set: 95% - 5%\n",
        "\t\tsplitIdx = int(0.95 * len(self.samples))\n",
        "\t\tself.trainSamples = self.samples[:splitIdx]\n",
        "\t\tself.validationSamples = self.samples[splitIdx:]\n",
        "\n",
        "\t\t# put words into lists\n",
        "\t\tself.trainWords = [x.gtText for x in self.trainSamples]\n",
        "\t\tself.validationWords = [x.gtText for x in self.validationSamples]\n",
        "\n",
        "\t\t# number of randomly chosen samples per epoch for training \n",
        "\t\tself.numTrainSamplesPerEpoch = 25000 \n",
        "\t\t\n",
        "\t\t# start with train set\n",
        "\t\tself.trainSet()\n",
        "\n",
        "\t\t# list of all chars in dataset\n",
        "\t\tself.charList = sorted(list(chars))\n",
        "\n",
        "\n",
        "\tdef truncateLabel(self, text, maxTextLen):\n",
        "\t\t# ctc_loss can't compute loss if it cannot find a mapping between text label and input \n",
        "\t\t# labels. Repeat letters cost double because of the blank symbol needing to be inserted.\n",
        "\t\t# If a too-long label is provided, ctc_loss returns an infinite gradient\n",
        "\t\tcost = 0\n",
        "\t\tfor i in range(len(text)):\n",
        "\t\t\tif i != 0 and text[i] == text[i-1]:\n",
        "\t\t\t\tcost += 2\n",
        "\t\t\telse:\n",
        "\t\t\t\tcost += 1\n",
        "\t\t\tif cost > maxTextLen:\n",
        "\t\t\t\treturn text[:i]\n",
        "\t\treturn text\n",
        "\n",
        "\n",
        "\tdef trainSet(self):\n",
        "\t\t\"switch to randomly chosen subset of training set\"\n",
        "\t\tself.dataAugmentation = True\n",
        "\t\tself.currIdx = 0\n",
        "\t\trandom.shuffle(self.trainSamples)\n",
        "\t\tself.samples = self.trainSamples[:self.numTrainSamplesPerEpoch]\n",
        "\n",
        "\t\n",
        "\tdef validationSet(self):\n",
        "\t\t\"switch to validation set\"\n",
        "\t\tself.dataAugmentation = False\n",
        "\t\tself.currIdx = 0\n",
        "\t\tself.samples = self.validationSamples\n",
        "\n",
        "\n",
        "\tdef getIteratorInfo(self):\n",
        "\t\t\"current batch index and overall number of batches\"\n",
        "\t\treturn (self.currIdx // self.batchSize + 1, len(self.samples) // self.batchSize)\n",
        "\n",
        "\n",
        "\tdef hasNext(self):\n",
        "\t\t\"iterator\"\n",
        "\t\treturn self.currIdx + self.batchSize <= len(self.samples)\n",
        "\t\t\n",
        "\t\t\n",
        "\tdef getNext(self):\n",
        "\t\t\"iterator\"\n",
        "\t\tbatchRange = range(self.currIdx, self.currIdx + self.batchSize)\n",
        "\t\tgtTexts = [self.samples[i].gtText for i in batchRange]\n",
        "\t\timgs = [preprocess(cv2.imread(self.samples[i].filePath, cv2.IMREAD_GRAYSCALE), self.imgSize, self.dataAugmentation) for i in batchRange]\n",
        "\t\tself.currIdx += self.batchSize\n",
        "\t\treturn Batch(gtTexts, imgs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MEPY-UG2kDtQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Model"
      ]
    },
    {
      "metadata": {
        "id": "wZhdnHTKkEtt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DecoderType:\n",
        "\tBestPath = 0\n",
        "\tBeamSearch = 1\n",
        "\tWordBeamSearch = 2\n",
        "\n",
        "\n",
        "class Model: \n",
        "\t\"minimalistic TF model for HTR\"\n",
        "\n",
        "\t# model constants\n",
        "\tbatchSize = 50\n",
        "\timgSize = (128, 32)\n",
        "\tmaxTextLen = 32\n",
        "\n",
        "\tdef __init__(self, charList, decoderType=DecoderType.BestPath, mustRestore=False):\n",
        "\t\t\"init model: add CNN, RNN and CTC and initialize TF\"\n",
        "\t\tself.charList = charList\n",
        "\t\tself.decoderType = decoderType\n",
        "\t\tself.mustRestore = mustRestore\n",
        "\t\tself.snapID = 0\n",
        "\n",
        "\t\t# Whether to use normalization over a batch or a population\n",
        "\t\tself.is_train = tf.placeholder(tf.bool, name='is_train')\n",
        "\n",
        "\t\t# input image batch\n",
        "\t\tself.inputImgs = tf.placeholder(tf.float32, shape=(None, Model.imgSize[0], Model.imgSize[1]))\n",
        "\n",
        "\t\t# setup CNN, RNN and CTC\n",
        "\t\tself.setupCNN()\n",
        "\t\tself.setupRNN()\n",
        "\t\tself.setupCTC()\n",
        "\n",
        "\t\t# setup optimizer to train NN\n",
        "\t\tself.batchesTrained = 0\n",
        "\t\tself.learningRate = tf.placeholder(tf.float32, shape=[])\n",
        "\t\tself.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \n",
        "\t\twith tf.control_dependencies(self.update_ops):\n",
        "\t\t\tself.optimizer = tf.train.RMSPropOptimizer(self.learningRate).minimize(self.loss)\n",
        "\n",
        "\t\t# initialize TF\n",
        "\t\t(self.sess, self.saver) = self.setupTF()\n",
        "\n",
        "\t\t\t\n",
        "\tdef setupCNN(self):\n",
        "\t\t\"create CNN layers and return output of these layers\"\n",
        "\t\tcnnIn4d = tf.expand_dims(input=self.inputImgs, axis=3)\n",
        "\n",
        "\t\t# list of parameters for the layers\n",
        "\t\tkernelVals = [5, 5, 3, 3, 3]\n",
        "\t\tfeatureVals = [1, 32, 64, 128, 128, 256]\n",
        "\t\tstrideVals = poolVals = [(2,2), (2,2), (1,2), (1,2), (1,2)]\n",
        "\t\tnumLayers = len(strideVals)\n",
        "\n",
        "\t\t# create layers\n",
        "\t\tpool = cnnIn4d # input to first CNN layer\n",
        "\t\tfor i in range(numLayers):\n",
        "\t\t\tkernel = tf.Variable(tf.truncated_normal([kernelVals[i], kernelVals[i], featureVals[i], featureVals[i + 1]], stddev=0.1))\n",
        "\t\t\tconv = tf.nn.conv2d(pool, kernel, padding='SAME',  strides=(1,1,1,1))\n",
        "\t\t\tconv_norm = tf.layers.batch_normalization(conv, training=self.is_train)\n",
        "\t\t\trelu = tf.nn.relu(conv_norm)\n",
        "\t\t\tpool = tf.nn.max_pool(relu, (1, poolVals[i][0], poolVals[i][1], 1), (1, strideVals[i][0], strideVals[i][1], 1), 'VALID')\n",
        "\n",
        "\t\tself.cnnOut4d = pool\n",
        "\n",
        "\n",
        "\tdef setupRNN(self):\n",
        "\t\t\"create RNN layers and return output of these layers\"\n",
        "\t\trnnIn3d = tf.squeeze(self.cnnOut4d, axis=[2])\n",
        "\n",
        "\t\t# basic cells which is used to build RNN\n",
        "\t\tnumHidden = 256\n",
        "\t\tcells = [tf.contrib.rnn.LSTMCell(num_units=numHidden, state_is_tuple=True) for _ in range(2)] # 2 layers\n",
        "\n",
        "\t\t# stack basic cells\n",
        "\t\tstacked = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
        "\n",
        "\t\t# bidirectional RNN\n",
        "\t\t# BxTxF -> BxTx2H\n",
        "\t\t((fw, bw), _) = tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked, cell_bw=stacked, inputs=rnnIn3d, dtype=rnnIn3d.dtype)\n",
        "\t\t\t\t\t\t\t\t\t\n",
        "\t\t# BxTxH + BxTxH -> BxTx2H -> BxTx1X2H\n",
        "\t\tconcat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n",
        "\t\t\t\t\t\t\t\t\t\n",
        "\t\t# project output to chars (including blank): BxTx1x2H -> BxTx1xC -> BxTxC\n",
        "\t\tkernel = tf.Variable(tf.truncated_normal([1, 1, numHidden * 2, len(self.charList) + 1], stddev=0.1))\n",
        "\t\tself.rnnOut3d = tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])\n",
        "\t\t\n",
        "\n",
        "\tdef setupCTC(self):\n",
        "\t\t\"create CTC loss and decoder and return them\"\n",
        "\t\t# BxTxC -> TxBxC\n",
        "\t\tself.ctcIn3dTBC = tf.transpose(self.rnnOut3d, [1, 0, 2])\n",
        "\t\t# ground truth text as sparse tensor\n",
        "\t\tself.gtTexts = tf.SparseTensor(tf.placeholder(tf.int64, shape=[None, 2]) , tf.placeholder(tf.int32, [None]), tf.placeholder(tf.int64, [2]))\n",
        "\n",
        "\t\t# calc loss for batch\n",
        "\t\tself.seqLen = tf.placeholder(tf.int32, [None])\n",
        "\t\tself.loss = tf.reduce_mean(tf.nn.ctc_loss(labels=self.gtTexts, inputs=self.ctcIn3dTBC, sequence_length=self.seqLen, ctc_merge_repeated=True))\n",
        "\n",
        "\t\t# calc loss for each element to compute label probability\n",
        "\t\tself.savedCtcInput = tf.placeholder(tf.float32, shape=[Model.maxTextLen, None, len(self.charList) + 1])\n",
        "\t\tself.lossPerElement = tf.nn.ctc_loss(labels=self.gtTexts, inputs=self.savedCtcInput, sequence_length=self.seqLen, ctc_merge_repeated=True)\n",
        "\n",
        "\t\t# decoder: either best path decoding or beam search decoding\n",
        "\t\tif self.decoderType == DecoderType.BestPath:\n",
        "\t\t\tself.decoder = tf.nn.ctc_greedy_decoder(inputs=self.ctcIn3dTBC, sequence_length=self.seqLen)\n",
        "\t\telif self.decoderType == DecoderType.BeamSearch:\n",
        "\t\t\tself.decoder = tf.nn.ctc_beam_search_decoder(inputs=self.ctcIn3dTBC, sequence_length=self.seqLen, beam_width=50, merge_repeated=False)\n",
        "\t\telif self.decoderType == DecoderType.WordBeamSearch:\n",
        "\t\t\t# import compiled word beam search operation (see https://github.com/githubharald/CTCWordBeamSearch)\n",
        "\t\t\tword_beam_search_module = tf.load_op_library('TFWordBeamSearch.so')\n",
        "\n",
        "\t\t\t# prepare information about language (dictionary, characters in dataset, characters forming words) \n",
        "\t\t\tchars = str().join(self.charList)\n",
        "\t\t\twordChars = open('../model/wordCharList.txt').read().splitlines()[0]\n",
        "\t\t\tcorpus = open('../data/corpus.txt').read()\n",
        "\n",
        "\t\t\t# decode using the \"Words\" mode of word beam search\n",
        "\t\t\tself.decoder = word_beam_search_module.word_beam_search(tf.nn.softmax(self.ctcIn3dTBC, dim=2), 50, 'Words', 0.0, corpus.encode('utf8'), chars.encode('utf8'), wordChars.encode('utf8'))\n",
        "\n",
        "\n",
        "\tdef setupTF(self):\n",
        "\t\t\"initialize TF\"\n",
        "\t\tprint('Python: '+sys.version)\n",
        "\t\tprint('Tensorflow: '+tf.__version__)\n",
        "\n",
        "\t\tsess=tf.Session() # TF session\n",
        "\n",
        "\t\tsaver = tf.train.Saver(max_to_keep=1) # saver saves model to file\n",
        "\t\tmodelDir = '../model/'\n",
        "\t\tlatestSnapshot = tf.train.latest_checkpoint(modelDir) # is there a saved model?\n",
        "\n",
        "\t\t# if model must be restored (for inference), there must be a snapshot\n",
        "\t\tif self.mustRestore and not latestSnapshot:\n",
        "\t\t\traise Exception('No saved model found in: ' + modelDir)\n",
        "\n",
        "\t\t# load saved model if available\n",
        "\t\tif latestSnapshot:\n",
        "\t\t\tprint('Init with stored values from ' + latestSnapshot)\n",
        "\t\t\tsaver.restore(sess, latestSnapshot)\n",
        "\t\telse:\n",
        "\t\t\tprint('Init with new values')\n",
        "\t\t\tsess.run(tf.global_variables_initializer())\n",
        "\n",
        "\t\treturn (sess,saver)\n",
        "\n",
        "\n",
        "\tdef toSparse(self, texts):\n",
        "\t\t\"put ground truth texts into sparse tensor for ctc_loss\"\n",
        "\t\tindices = []\n",
        "\t\tvalues = []\n",
        "\t\tshape = [len(texts), 0] # last entry must be max(labelList[i])\n",
        "\n",
        "\t\t# go over all texts\n",
        "\t\tfor (batchElement, text) in enumerate(texts):\n",
        "\t\t\t# convert to string of label (i.e. class-ids)\n",
        "\t\t\tlabelStr = [self.charList.index(c) for c in text]\n",
        "\t\t\t# sparse tensor must have size of max. label-string\n",
        "\t\t\tif len(labelStr) > shape[1]:\n",
        "\t\t\t\tshape[1] = len(labelStr)\n",
        "\t\t\t# put each label into sparse tensor\n",
        "\t\t\tfor (i, label) in enumerate(labelStr):\n",
        "\t\t\t\tindices.append([batchElement, i])\n",
        "\t\t\t\tvalues.append(label)\n",
        "\n",
        "\t\treturn (indices, values, shape)\n",
        "\n",
        "\n",
        "\tdef decoderOutputToText(self, ctcOutput, batchSize):\n",
        "\t\t\"extract texts from output of CTC decoder\"\n",
        "\t\t\n",
        "\t\t# contains string of labels for each batch element\n",
        "\t\tencodedLabelStrs = [[] for i in range(batchSize)]\n",
        "\n",
        "\t\t# word beam search: label strings terminated by blank\n",
        "\t\tif self.decoderType == DecoderType.WordBeamSearch:\n",
        "\t\t\tblank=len(self.charList)\n",
        "\t\t\tfor b in range(batchSize):\n",
        "\t\t\t\tfor label in ctcOutput[b]:\n",
        "\t\t\t\t\tif label==blank:\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\tencodedLabelStrs[b].append(label)\n",
        "\n",
        "\t\t# TF decoders: label strings are contained in sparse tensor\n",
        "\t\telse:\n",
        "\t\t\t# ctc returns tuple, first element is SparseTensor \n",
        "\t\t\tdecoded=ctcOutput[0][0] \n",
        "\n",
        "\t\t\t# go over all indices and save mapping: batch -> values\n",
        "\t\t\tidxDict = { b : [] for b in range(batchSize) }\n",
        "\t\t\tfor (idx, idx2d) in enumerate(decoded.indices):\n",
        "\t\t\t\tlabel = decoded.values[idx]\n",
        "\t\t\t\tbatchElement = idx2d[0] # index according to [b,t]\n",
        "\t\t\t\tencodedLabelStrs[batchElement].append(label)\n",
        "\n",
        "\t\t# map labels to chars for all batch elements\n",
        "\t\treturn [str().join([self.charList[c] for c in labelStr]) for labelStr in encodedLabelStrs]\n",
        "\n",
        "\n",
        "\tdef trainBatch(self, batch):\n",
        "\t\t\"feed a batch into the NN to train it\"\n",
        "\t\tnumBatchElements = len(batch.imgs)\n",
        "\t\tsparse = self.toSparse(batch.gtTexts)\n",
        "\t\trate = 0.01 if self.batchesTrained < 10 else (0.001 if self.batchesTrained < 10000 else 0.0001) # decay learning rate\n",
        "\t\tevalList = [self.optimizer, self.loss]\n",
        "\t\tfeedDict = {self.inputImgs : batch.imgs, self.gtTexts : sparse , self.seqLen : [Model.maxTextLen] * numBatchElements, self.learningRate : rate, self.is_train: True}\n",
        "\t\t(_, lossVal) = self.sess.run(evalList, feedDict)\n",
        "\t\tself.batchesTrained += 1\n",
        "\t\treturn lossVal\n",
        "\n",
        "\n",
        "\tdef inferBatch(self, batch, calcProbability=False, probabilityOfGT=False):\n",
        "\t\t\"feed a batch into the NN to recognize the texts\"\n",
        "\t\t\n",
        "\t\t# decode, optionally save RNN output\n",
        "\t\tnumBatchElements = len(batch.imgs)\n",
        "\t\tevalList = [self.decoder] + ([self.ctcIn3dTBC] if calcProbability else [])\n",
        "\t\tfeedDict = {self.inputImgs : batch.imgs, self.seqLen : [Model.maxTextLen] * numBatchElements, self.is_train: False}\n",
        "\t\tevalRes = self.sess.run([self.decoder, self.ctcIn3dTBC], feedDict)\n",
        "\t\tdecoded = evalRes[0]\n",
        "\t\ttexts = self.decoderOutputToText(decoded, numBatchElements)\n",
        "\t\t\n",
        "\t\t# feed RNN output and recognized text into CTC loss to compute labeling probability\n",
        "\t\tprobs = None\n",
        "\t\tif calcProbability:\n",
        "\t\t\tsparse = self.toSparse(batch.gtTexts) if probabilityOfGT else self.toSparse(texts)\n",
        "\t\t\tctcInput = evalRes[1]\n",
        "\t\t\tevalList = self.lossPerElement\n",
        "\t\t\tfeedDict = {self.savedCtcInput : ctcInput, self.gtTexts : sparse, self.seqLen : [Model.maxTextLen] * numBatchElements, self.is_train: False}\n",
        "\t\t\tlossVals = self.sess.run(evalList, feedDict)\n",
        "\t\t\tprobs = np.exp(-lossVals)\n",
        "\t\treturn (texts, probs)\n",
        "\t\n",
        "\n",
        "\tdef save(self):\n",
        "\t\t\"save model to file\"\n",
        "\t\tself.snapID += 1\n",
        "\t\tself.saver.save(self.sess, '../model/snapshot', global_step=self.snapID)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ipcZOyc0kdf0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FilePaths:\n",
        "\t\"filenames and paths to data\"\n",
        "\tfnCharList = '../model/charList.txt'\n",
        "\tfnAccuracy = '../model/accuracy.txt'\n",
        "\tfnTrain = '../data/'\n",
        "\tfnInfer = '../data/test.png'\n",
        "\tfnCorpus = '../data/corpus.txt'\n",
        "\n",
        "\n",
        "def train(model, loader):\n",
        "\t\"train NN\"\n",
        "\tepoch = 0 # number of training epochs since start\n",
        "\tbestCharErrorRate = float('inf') # best valdiation character error rate\n",
        "\tnoImprovementSince = 0 # number of epochs no improvement of character error rate occured\n",
        "\tearlyStopping = 5 # stop training after this number of epochs without improvement\n",
        "\twhile True:\n",
        "\t\tepoch += 1\n",
        "\t\tprint('Epoch:', epoch)\n",
        "\n",
        "\t\t# train\n",
        "\t\tprint('Train NN')\n",
        "\t\tloader.trainSet()\n",
        "\t\twhile loader.hasNext():\n",
        "\t\t\titerInfo = loader.getIteratorInfo()\n",
        "\t\t\tbatch = loader.getNext()\n",
        "\t\t\tloss = model.trainBatch(batch)\n",
        "\t\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1], 'Loss:', loss)\n",
        "\n",
        "\t\t# validate\n",
        "\t\tcharErrorRate = validate(model, loader)\n",
        "\t\t\n",
        "\t\t# if best validation accuracy so far, save model parameters\n",
        "\t\tif charErrorRate < bestCharErrorRate:\n",
        "\t\t\tprint('Character error rate improved, save model')\n",
        "\t\t\tbestCharErrorRate = charErrorRate\n",
        "\t\t\tnoImprovementSince = 0\n",
        "\t\t\tmodel.save()\n",
        "\t\t\topen(FilePaths.fnAccuracy, 'w').write('Validation character error rate of saved model: %f%%' % (charErrorRate*100.0))\n",
        "\t\telse:\n",
        "\t\t\tprint('Character error rate not improved')\n",
        "\t\t\tnoImprovementSince += 1\n",
        "\n",
        "\t\t# stop training if no more improvement in the last x epochs\n",
        "\t\tif noImprovementSince >= earlyStopping:\n",
        "\t\t\tprint('No more improvement since %d epochs. Training stopped.' % earlyStopping)\n",
        "\t\t\tbreak\n",
        "\n",
        "\n",
        "def validate(model, loader):\n",
        "\t\"validate NN\"\n",
        "\tprint('Validate NN')\n",
        "\tloader.validationSet()\n",
        "\tnumCharErr = 0\n",
        "\tnumCharTotal = 0\n",
        "\tnumWordOK = 0\n",
        "\tnumWordTotal = 0\n",
        "\twhile loader.hasNext():\n",
        "\t\titerInfo = loader.getIteratorInfo()\n",
        "\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1])\n",
        "\t\tbatch = loader.getNext()\n",
        "\t\t(recognized, _) = model.inferBatch(batch)\n",
        "\t\t\n",
        "\t\tprint('Ground truth -> Recognized')\t\n",
        "\t\tfor i in range(len(recognized)):\n",
        "\t\t\tnumWordOK += 1 if batch.gtTexts[i] == recognized[i] else 0\n",
        "\t\t\tnumWordTotal += 1\n",
        "\t\t\tdist = editdistance.eval(recognized[i], batch.gtTexts[i])\n",
        "\t\t\tnumCharErr += dist\n",
        "\t\t\tnumCharTotal += len(batch.gtTexts[i])\n",
        "\t\t\tprint('[OK]' if dist==0 else '[ERR:%d]' % dist,'\"' + batch.gtTexts[i] + '\"', '->', '\"' + recognized[i] + '\"')\n",
        "\t\n",
        "\t# print validation result\n",
        "\tcharErrorRate = numCharErr / numCharTotal\n",
        "\twordAccuracy = numWordOK / numWordTotal\n",
        "\tprint('Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate*100.0, wordAccuracy*100.0))\n",
        "\treturn charErrorRate\n",
        "\n",
        "\n",
        "def infer(model, fnImg):\n",
        "\t\"recognize text in image provided by file path\"\n",
        "\timg = preprocess(cv2.imread(fnImg, cv2.IMREAD_GRAYSCALE), Model.imgSize)\n",
        "\tbatch = Batch(None, [img])\n",
        "\t(recognized, probability) = model.inferBatch(batch, True)\n",
        "\tprint('Recognized:', '\"' + recognized[0] + '\"')\n",
        "\tprint('Probability:', probability[0])\n",
        "\n",
        "\n",
        "def main():\n",
        "\t\"main function\"\n",
        "\t# optional command line args\n",
        "\tparser = argparse.ArgumentParser()\n",
        "\tparser.add_argument('--train', help='train the NN', action='store_true')\n",
        "\tparser.add_argument('--validate', help='validate the NN', action='store_true')\n",
        "\tparser.add_argument('--beamsearch', help='use beam search instead of best path decoding', action='store_true')\n",
        "\tparser.add_argument('--wordbeamsearch', help='use word beam search instead of best path decoding', action='store_true')\n",
        "\targs = parser.parse_args()\n",
        "\n",
        "\tdecoderType = DecoderType.BestPath\n",
        "\tif args.beamsearch:\n",
        "\t\tdecoderType = DecoderType.BeamSearch\n",
        "\telif args.wordbeamsearch:\n",
        "\t\tdecoderType = DecoderType.WordBeamSearch\n",
        "\n",
        "\t# train or validate on IAM dataset\t\n",
        "\tif args.train or args.validate:\n",
        "\t\t# load training data, create TF model\n",
        "\t\tloader = DataLoader(FilePaths.fnTrain, Model.batchSize, Model.imgSize, Model.maxTextLen)\n",
        "\n",
        "\t\t# save characters of model for inference mode\n",
        "\t\topen(FilePaths.fnCharList, 'w').write(str().join(loader.charList))\n",
        "\t\t\n",
        "\t\t# save words contained in dataset into file\n",
        "\t\topen(FilePaths.fnCorpus, 'w').write(str(' ').join(loader.trainWords + loader.validationWords))\n",
        "\n",
        "\t\t# execute training or validation\n",
        "\t\tif args.train:\n",
        "\t\t\tmodel = Model(loader.charList, decoderType)\n",
        "\t\t\ttrain(model, loader)\n",
        "\t\telif args.validate:\n",
        "\t\t\tmodel = Model(loader.charList, decoderType, mustRestore=True)\n",
        "\t\t\tvalidate(model, loader)\n",
        "\n",
        "\t# infer text on test image\n",
        "\telse:\n",
        "\t\tprint(open(FilePaths.fnAccuracy).read())\n",
        "\t\tmodel = Model(open(FilePaths.fnCharList).read(), decoderType, mustRestore=True)\n",
        "\t\tinfer(model, FilePaths.fnInfer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}